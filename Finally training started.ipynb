{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPGt9zt2wcB6VgY9lDDv1no",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammad-usama-aleem/Object-Detection-using-tensorflow-api/blob/main/Finally%20training%20started.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKZu9hQpqOQE",
        "outputId": "184e36a4-1c55-4a34-bc9c-930b17499327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 69331, done.\u001b[K\n",
            "remote: Total 69331 (delta 0), reused 0 (delta 0), pack-reused 69331\u001b[K\n",
            "Receiving objects: 100% (69331/69331), 577.32 MiB | 27.60 MiB/s, done.\n",
            "Resolving deltas: 100% (48851/48851), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7vaHe8_ezpf",
        "outputId": "1b855b1a-0252-484c-bf67-bda215e887ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "images_dir = \"/content/gdrive/MyDrive/car_ims/car_ims/car_ims/\"\n",
        "path, dirs, files = next(os.walk(\"/content/gdrive/MyDrive/car_ims/car_ims/car_ims\"))\n",
        "file_count = len(files)\n",
        "print(file_count)\n",
        "print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3Jp3H-VZcuq",
        "outputId": "6cc48588-ba65-4cd9-e36a-381ce913f825"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16185\n",
            "/content/gdrive/MyDrive/car_ims/car_ims/car_ims\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import loadmat\n",
        "import cv2\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "resp = loadmat(\"/content/cars_annos.mat\")"
      ],
      "metadata": {
        "id": "LiUPtlA4Dhu0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM5z8STnDqY-",
        "outputId": "831cff98-5755-4bc5-ddfe-48e033b6d58d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['__header__', '__version__', '__globals__', 'annotations', 'class_names'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resp.get(\"annotations\")[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM9QLAztUYUI",
        "outputId": "47df470e-9f70-46e2-8e55-137c585083f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([(array(['car_ims/000001.jpg'], dtype='<U18'), array([[112]], dtype=uint8), array([[7]], dtype=uint8), array([[853]], dtype=uint16), array([[717]], dtype=uint16), array([[1]], dtype=uint8), array([[0]], dtype=uint8)),\n",
              "       (array(['car_ims/000002.jpg'], dtype='<U18'), array([[48]], dtype=uint8), array([[24]], dtype=uint8), array([[441]], dtype=uint16), array([[202]], dtype=uint8), array([[1]], dtype=uint8), array([[0]], dtype=uint8)),\n",
              "       (array(['car_ims/000003.jpg'], dtype='<U18'), array([[7]], dtype=uint8), array([[4]], dtype=uint8), array([[277]], dtype=uint16), array([[180]], dtype=uint8), array([[1]], dtype=uint8), array([[0]], dtype=uint8)),\n",
              "       ...,\n",
              "       (array(['car_ims/016183.jpg'], dtype='<U18'), array([[25]], dtype=uint8), array([[32]], dtype=uint8), array([[587]], dtype=uint16), array([[359]], dtype=uint16), array([[196]], dtype=uint8), array([[1]], dtype=uint8)),\n",
              "       (array(['car_ims/016184.jpg'], dtype='<U18'), array([[56]], dtype=uint8), array([[60]], dtype=uint8), array([[208]], dtype=uint8), array([[186]], dtype=uint8), array([[196]], dtype=uint8), array([[1]], dtype=uint8)),\n",
              "       (array(['car_ims/016185.jpg'], dtype='<U18'), array([[1]], dtype=uint8), array([[1]], dtype=uint8), array([[200]], dtype=uint8), array([[131]], dtype=uint8), array([[196]], dtype=uint8), array([[1]], dtype=uint8))],\n",
              "      dtype=[('relative_im_path', 'O'), ('bbox_x1', 'O'), ('bbox_y1', 'O'), ('bbox_x2', 'O'), ('bbox_y2', 'O'), ('class', 'O'), ('test', 'O')])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(resp.get(\"annotations\")[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M7RuaRPDwuh",
        "outputId": "7e302ec0-b9b1-43b2-dedd-f2e174d897a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16185"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(resp.get(\"class_names\")[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcgAawOxDzY0",
        "outputId": "b7198ff3-dd67-495a-82a2-c4bd52d4d8e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "196"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = []\n",
        "for class_name in resp.get(\"class_names\")[0]:\n",
        "    classes.append(class_name[0]) "
      ],
      "metadata": {
        "id": "LNo1od0uEL_X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create CSV File**"
      ],
      "metadata": {
        "id": "zOn8x-X8IC0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(test_type, directory):\n",
        "    data = []\n",
        "    if not os.path.exists(directory): os.mkdir(directory)\n",
        "    for annot in resp.get(\"annotations\")[0]:\n",
        "        test = int(annot[6][0][0])\n",
        "        if test == test_type: continue\n",
        "\n",
        "\n",
        "        image_name = annot[0][0].split(\"/\")[-1]\n",
        "        print(image_name)\n",
        "        image = cv2.imread(images_dir + image_name)\n",
        "        shutil.copy(images_dir + image_name, f\"{directory}/\" + image_name)\n",
        "        h, w, _ = image.shape\n",
        "        xmin = int(annot[1][0][0])\n",
        "        ymin = int(annot[2][0][0])\n",
        "        xmax = int(annot[3][0][0])\n",
        "        ymax = int(annot[4][0][0])\n",
        "        class_name = classes[annot[5][0][0] - 1]\n",
        "\n",
        "        data.append({\n",
        "            'filename' : image_name, \"width\" : w, \"height\" : h, \n",
        "            'class' : class_name,\n",
        "            'xmin' : xmin, 'ymin' : ymin, 'xmax' : xmax, \n",
        "            'ymax' : ymax})\n",
        "        \n",
        "    df = pd.DataFrame(data)\n",
        "    return df"
      ],
      "metadata": {
        "id": "qT6MUfp2EYPm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/train"
      ],
      "metadata": {
        "id": "u9P1pota6lae"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get train data\n",
        "df = get_data(0, \"/content/train\")\n",
        "df.to_csv(\"train_labels.csv\", index=None)\n",
        "\n",
        "# Get train data\n",
        "df = get_data(1, \"/content/test\")\n",
        "df.to_csv(\"test_labels.csv\", index=None)"
      ],
      "metadata": {
        "id": "zumEDqS4VO69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "_, _, files = next(os.walk(\"/content/test\"))\n",
        "file_count = len(files)\n",
        "print(file_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq4cjJhENBqz",
        "outputId": "29555ad0-00b3-4383-9a50-277e96dcf889"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"labels.pbtxt\", \"w\") as file:\n",
        "    for index, cls in enumerate(classes):\n",
        "        row = \"item {\\n\\tid: \" + str(index + 1) + \"\\n\\tname: '\" + cls +\"'\\n}\\n\"\n",
        "        file.write(row)"
      ],
      "metadata": {
        "id": "S9mp3QAfNBnL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "paste this label dict in your '/content/models/research/preprocessing' generate_tfrecords.py\n",
        "OR\n",
        "make a labels.json file and use it in generate_tfrecords.py as we are going to do\n",
        "\n",
        "'''\n",
        "\n",
        "import json\n",
        "labels = {cls:i + 1 for i, cls in enumerate(classes)}\n",
        "with open('labels.json', \"w\") as file:\n",
        "    json.dump(labels, file)\n",
        "labels"
      ],
      "metadata": {
        "id": "ZBty7BwaNBL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0a6876-90b4-48f3-b58c-9c4815f4c483"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AM General Hummer SUV 2000': 1,\n",
              " 'Acura Integra Type R 2001': 6,\n",
              " 'Acura RL Sedan 2012': 2,\n",
              " 'Acura TL Sedan 2012': 3,\n",
              " 'Acura TL Type-S 2008': 4,\n",
              " 'Acura TSX Sedan 2012': 5,\n",
              " 'Acura ZDX Hatchback 2012': 7,\n",
              " 'Aston Martin V8 Vantage Convertible 2012': 8,\n",
              " 'Aston Martin V8 Vantage Coupe 2012': 9,\n",
              " 'Aston Martin Virage Convertible 2012': 10,\n",
              " 'Aston Martin Virage Coupe 2012': 11,\n",
              " 'Audi 100 Sedan 1994': 17,\n",
              " 'Audi 100 Wagon 1994': 18,\n",
              " 'Audi A5 Coupe 2012': 13,\n",
              " 'Audi R8 Coupe 2012': 15,\n",
              " 'Audi RS 4 Convertible 2008': 12,\n",
              " 'Audi S4 Sedan 2007': 24,\n",
              " 'Audi S4 Sedan 2012': 23,\n",
              " 'Audi S5 Convertible 2012': 21,\n",
              " 'Audi S5 Coupe 2012': 22,\n",
              " 'Audi S6 Sedan 2011': 20,\n",
              " 'Audi TT Hatchback 2011': 19,\n",
              " 'Audi TT RS Coupe 2012': 25,\n",
              " 'Audi TTS Coupe 2012': 14,\n",
              " 'Audi V8 Sedan 1994': 16,\n",
              " 'BMW 1 Series Convertible 2012': 27,\n",
              " 'BMW 1 Series Coupe 2012': 28,\n",
              " 'BMW 3 Series Sedan 2012': 29,\n",
              " 'BMW 3 Series Wagon 2012': 30,\n",
              " 'BMW 6 Series Convertible 2007': 31,\n",
              " 'BMW ActiveHybrid 5 Sedan 2012': 26,\n",
              " 'BMW M3 Coupe 2012': 34,\n",
              " 'BMW M5 Sedan 2010': 35,\n",
              " 'BMW M6 Convertible 2010': 36,\n",
              " 'BMW X3 SUV 2012': 37,\n",
              " 'BMW X5 SUV 2007': 32,\n",
              " 'BMW X6 SUV 2012': 33,\n",
              " 'BMW Z4 Convertible 2012': 38,\n",
              " 'Bentley Arnage Sedan 2009': 40,\n",
              " 'Bentley Continental Flying Spur Sedan 2007': 44,\n",
              " 'Bentley Continental GT Coupe 2007': 43,\n",
              " 'Bentley Continental GT Coupe 2012': 42,\n",
              " 'Bentley Continental Supersports Conv. Convertible 2012': 39,\n",
              " 'Bentley Mulsanne Sedan 2011': 41,\n",
              " 'Bugatti Veyron 16.4 Convertible 2009': 45,\n",
              " 'Bugatti Veyron 16.4 Coupe 2009': 46,\n",
              " 'Buick Enclave SUV 2012': 50,\n",
              " 'Buick Rainier SUV 2007': 48,\n",
              " 'Buick Regal GS 2012': 47,\n",
              " 'Buick Verano Sedan 2012': 49,\n",
              " 'Cadillac CTS-V Sedan 2012': 51,\n",
              " 'Cadillac Escalade EXT Crew Cab 2007': 53,\n",
              " 'Cadillac SRX SUV 2012': 52,\n",
              " 'Chevrolet Avalanche Crew Cab 2012': 65,\n",
              " 'Chevrolet Camaro Convertible 2012': 59,\n",
              " 'Chevrolet Cobalt SS 2010': 66,\n",
              " 'Chevrolet Corvette Convertible 2012': 55,\n",
              " 'Chevrolet Corvette Ron Fellows Edition Z06 2007': 57,\n",
              " 'Chevrolet Corvette ZR1 2012': 56,\n",
              " 'Chevrolet Express Cargo Van 2007': 64,\n",
              " 'Chevrolet Express Van 2007': 71,\n",
              " 'Chevrolet HHR SS 2010': 60,\n",
              " 'Chevrolet Impala Sedan 2007': 61,\n",
              " 'Chevrolet Malibu Hybrid Sedan 2010': 67,\n",
              " 'Chevrolet Malibu Sedan 2007': 73,\n",
              " 'Chevrolet Monte Carlo Coupe 2007': 72,\n",
              " 'Chevrolet Silverado 1500 Classic Extended Cab 2007': 70,\n",
              " 'Chevrolet Silverado 1500 Extended Cab 2012': 74,\n",
              " 'Chevrolet Silverado 1500 Hybrid Crew Cab 2012': 54,\n",
              " 'Chevrolet Silverado 1500 Regular Cab 2012': 75,\n",
              " 'Chevrolet Silverado 2500HD Regular Cab 2012': 69,\n",
              " 'Chevrolet Sonic Sedan 2012': 63,\n",
              " 'Chevrolet Tahoe Hybrid SUV 2012': 62,\n",
              " 'Chevrolet TrailBlazer SS 2009': 68,\n",
              " 'Chevrolet Traverse SUV 2012': 58,\n",
              " 'Chrysler 300 SRT-8 2010': 79,\n",
              " 'Chrysler Aspen SUV 2009': 76,\n",
              " 'Chrysler Crossfire Convertible 2008': 80,\n",
              " 'Chrysler PT Cruiser Convertible 2008': 81,\n",
              " 'Chrysler Sebring Convertible 2010': 77,\n",
              " 'Chrysler Town and Country Minivan 2012': 78,\n",
              " 'Daewoo Nubira Wagon 2002': 82,\n",
              " 'Dodge Caliber Wagon 2007': 84,\n",
              " 'Dodge Caliber Wagon 2012': 83,\n",
              " 'Dodge Caravan Minivan 1997': 85,\n",
              " 'Dodge Challenger SRT8 2011': 93,\n",
              " 'Dodge Charger SRT-8 2009': 97,\n",
              " 'Dodge Charger Sedan 2012': 96,\n",
              " 'Dodge Dakota Club Cab 2007': 91,\n",
              " 'Dodge Dakota Crew Cab 2010': 90,\n",
              " 'Dodge Durango SUV 2007': 95,\n",
              " 'Dodge Durango SUV 2012': 94,\n",
              " 'Dodge Journey SUV 2012': 89,\n",
              " 'Dodge Magnum Wagon 2008': 92,\n",
              " 'Dodge Ram Pickup 3500 Crew Cab 2010': 86,\n",
              " 'Dodge Ram Pickup 3500 Quad Cab 2009': 87,\n",
              " 'Dodge Sprinter Cargo Van 2009': 88,\n",
              " 'Eagle Talon Hatchback 1998': 98,\n",
              " 'FIAT 500 Abarth 2012': 99,\n",
              " 'FIAT 500 Convertible 2012': 100,\n",
              " 'Ferrari 458 Italia Convertible 2012': 103,\n",
              " 'Ferrari 458 Italia Coupe 2012': 104,\n",
              " 'Ferrari California Convertible 2012': 102,\n",
              " 'Ferrari FF Coupe 2012': 101,\n",
              " 'Fisker Karma Sedan 2012': 105,\n",
              " 'Ford E-Series Wagon Van 2012': 116,\n",
              " 'Ford Edge SUV 2012': 110,\n",
              " 'Ford Expedition EL SUV 2009': 109,\n",
              " 'Ford F-150 Regular Cab 2007': 114,\n",
              " 'Ford F-150 Regular Cab 2012': 113,\n",
              " 'Ford F-450 Super Duty Crew Cab 2012': 106,\n",
              " 'Ford Fiesta Sedan 2012': 117,\n",
              " 'Ford Focus Sedan 2007': 115,\n",
              " 'Ford Freestar Minivan 2007': 108,\n",
              " 'Ford GT Coupe 2006': 112,\n",
              " 'Ford Mustang Convertible 2007': 107,\n",
              " 'Ford Ranger SuperCab 2011': 111,\n",
              " 'GMC Acadia SUV 2012': 121,\n",
              " 'GMC Canyon Extended Cab 2012': 122,\n",
              " 'GMC Savana Van 2012': 119,\n",
              " 'GMC Terrain SUV 2012': 118,\n",
              " 'GMC Yukon Hybrid SUV 2012': 120,\n",
              " 'Geo Metro Convertible 1993': 123,\n",
              " 'HUMMER H2 SUT Crew Cab 2009': 125,\n",
              " 'HUMMER H3T Crew Cab 2010': 124,\n",
              " 'Honda Accord Coupe 2012': 128,\n",
              " 'Honda Accord Sedan 2012': 129,\n",
              " 'Honda Odyssey Minivan 2007': 127,\n",
              " 'Honda Odyssey Minivan 2012': 126,\n",
              " 'Hyundai Accent Sedan 2012': 136,\n",
              " 'Hyundai Azera Sedan 2012': 140,\n",
              " 'Hyundai Elantra Sedan 2007': 135,\n",
              " 'Hyundai Elantra Touring Hatchback 2012': 139,\n",
              " 'Hyundai Genesis Sedan 2012': 137,\n",
              " 'Hyundai Santa Fe SUV 2012': 131,\n",
              " 'Hyundai Sonata Hybrid Sedan 2012': 134,\n",
              " 'Hyundai Sonata Sedan 2012': 138,\n",
              " 'Hyundai Tucson SUV 2012': 132,\n",
              " 'Hyundai Veloster Hatchback 2012': 130,\n",
              " 'Hyundai Veracruz SUV 2012': 133,\n",
              " 'Infiniti G Coupe IPL 2012': 141,\n",
              " 'Infiniti QX56 SUV 2011': 142,\n",
              " 'Isuzu Ascender SUV 2008': 143,\n",
              " 'Jaguar XK XKR 2012': 144,\n",
              " 'Jeep Compass SUV 2012': 149,\n",
              " 'Jeep Grand Cherokee SUV 2012': 148,\n",
              " 'Jeep Liberty SUV 2012': 147,\n",
              " 'Jeep Patriot SUV 2012': 145,\n",
              " 'Jeep Wrangler SUV 2012': 146,\n",
              " 'Lamborghini Aventador Coupe 2012': 151,\n",
              " 'Lamborghini Diablo Coupe 2001': 153,\n",
              " 'Lamborghini Gallardo LP 570-4 Superleggera 2012': 152,\n",
              " 'Lamborghini Reventon Coupe 2008': 150,\n",
              " 'Land Rover LR2 SUV 2012': 155,\n",
              " 'Land Rover Range Rover SUV 2012': 154,\n",
              " 'Lincoln Town Car Sedan 2011': 156,\n",
              " 'MINI Cooper Roadster Convertible 2012': 157,\n",
              " 'Maybach Landaulet Convertible 2012': 158,\n",
              " 'Mazda Tribute SUV 2011': 159,\n",
              " 'McLaren MP4-12C Coupe 2012': 160,\n",
              " 'Mercedes-Benz 300-Class Convertible 1993': 161,\n",
              " 'Mercedes-Benz C-Class Sedan 2012': 162,\n",
              " 'Mercedes-Benz E-Class Sedan 2012': 164,\n",
              " 'Mercedes-Benz S-Class Sedan 2012': 165,\n",
              " 'Mercedes-Benz SL-Class Coupe 2009': 163,\n",
              " 'Mercedes-Benz Sprinter Van 2012': 166,\n",
              " 'Mitsubishi Lancer Sedan 2012': 167,\n",
              " 'Nissan 240SX Coupe 1998': 171,\n",
              " 'Nissan Juke Hatchback 2012': 170,\n",
              " 'Nissan Leaf Hatchback 2012': 168,\n",
              " 'Nissan NV Passenger Van 2012': 169,\n",
              " 'Plymouth Neon Coupe 1999': 172,\n",
              " 'Porsche Panamera Sedan 2012': 173,\n",
              " 'Ram C/V Cargo Van Minivan 2012': 174,\n",
              " 'Rolls-Royce Ghost Sedan 2012': 176,\n",
              " 'Rolls-Royce Phantom Drophead Coupe Convertible 2012': 175,\n",
              " 'Rolls-Royce Phantom Sedan 2012': 177,\n",
              " 'Scion xD Hatchback 2012': 178,\n",
              " 'Spyker C8 Convertible 2009': 179,\n",
              " 'Spyker C8 Coupe 2009': 180,\n",
              " 'Suzuki Aerio Sedan 2007': 181,\n",
              " 'Suzuki Kizashi Sedan 2012': 182,\n",
              " 'Suzuki SX4 Hatchback 2012': 183,\n",
              " 'Suzuki SX4 Sedan 2012': 184,\n",
              " 'Tesla Model S Sedan 2012': 185,\n",
              " 'Toyota 4Runner SUV 2012': 189,\n",
              " 'Toyota Camry Sedan 2012': 187,\n",
              " 'Toyota Corolla Sedan 2012': 188,\n",
              " 'Toyota Sequoia SUV 2012': 186,\n",
              " 'Volkswagen Beetle Hatchback 2012': 192,\n",
              " 'Volkswagen Golf Hatchback 1991': 191,\n",
              " 'Volkswagen Golf Hatchback 2012': 190,\n",
              " 'Volvo 240 Sedan 1993': 194,\n",
              " 'Volvo C30 Hatchback 2012': 193,\n",
              " 'Volvo XC90 SUV 2007': 195,\n",
              " 'smart fortwo Convertible 2012': 196}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Tfrecord file"
      ],
      "metadata": {
        "id": "1ACZjOuul-uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/models"
      ],
      "metadata": {
        "id": "O_nl7w4zp_qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTvRO8TGq2LA",
        "outputId": "1eeabbf4-aa11-4d73-b59f-837b3eea5941"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KeLY_BesDvK",
        "outputId": "de42a1d8-8bbf-474b-df56-0e0ab63ee08e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZmCO4eA6EK0",
        "outputId": "bc843ba3-698f-43a6-cf77-2a012c171bad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkkoVMGmoPmT",
        "outputId": "32184519-f4b8-44aa-eacc-50e36a45406d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.36.0-cp37-cp37m-manylinux2010_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 34.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 482 kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.1-py2.py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 47.4 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 71 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.10)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 31.5 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.8.0\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 32.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.54.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.24.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.43.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 41.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 43.9 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.7-cp37-cp37m-manylinux_2_24_x86_64.whl (255 kB)\n",
            "\u001b[K     |████████████████████████████████| 255 kB 44.6 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[K     |████████████████████████████████| 508 kB 45.6 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 35.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Collecting protobuf>=3.12.0\n",
            "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 40.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.6.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1686356 sha256=fb06879278b1bc82f9f6e4f1c846fc87b3e2c902a7edf60162923d90164f40ae\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yyclxlrt/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=731a828cc5f80d718b60782a81d9e31f05b969f1537a95ea1eb626adae8ad4ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=d64540b75e400f9b58df80dcfb6161eb392aa7ebb9fce844c7b87ce0c89d6ba6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=e4d3f6b8937fb5d268b26e8aa8b3accec2ca1b47133dfa6c371ff05dc2a05653\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=8d807a848cf8a8cfc02703dd126a5a2347e32cbce27f3f564c11468dd847d122\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n",
            "Installing collected packages: requests, protobuf, tf-estimator-nightly, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.0.1\n",
            "    Uninstalling pymongo-4.0.1:\n",
            "      Successfully uninstalled pymongo-4.0.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.36.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.9 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.62 orjson-3.6.7 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-io-0.24.0 tensorflow-model-optimization-0.7.1 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())\n",
        "# !python object_detection/builders/model_builder_tf1_test.py\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd2lalRx6MUx",
        "outputId": "5cecf218-cc29-4d12-9e8e-b52c99b8d195"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n",
            "Running tests under Python 3.7.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-02-26 07:36:58.863524: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0226 07:36:59.407399 140344161339264 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.88s\n",
            "I0226 07:36:59.766451 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.88s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.72s\n",
            "I0226 07:37:00.492035 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.72s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.37s\n",
            "I0226 07:37:00.862863 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.37s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.35s\n",
            "I0226 07:37:01.214956 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.35s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.77s\n",
            "I0226 07:37:03.980838 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.77s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0226 07:37:03.982164 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0226 07:37:04.013345 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0226 07:37:04.034437 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0226 07:37:04.055514 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "I0226 07:37:04.187592 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "I0226 07:37:04.319948 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.15s\n",
            "I0226 07:37:04.468553 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
            "I0226 07:37:04.602082 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n",
            "I0226 07:37:04.728149 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I0226 07:37:04.769692 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0226 07:37:05.016308 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0226 07:37:05.016524 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0226 07:37:05.016648 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0226 07:37:05.019479 140344161339264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0226 07:37:05.042242 140344161339264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0226 07:37:05.042454 140344161339264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0226 07:37:05.128012 140344161339264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0226 07:37:05.128232 140344161339264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0226 07:37:05.343907 140344161339264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0226 07:37:05.344122 140344161339264 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0226 07:37:05.557698 140344161339264 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0226 07:37:05.557944 140344161339264 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0226 07:37:05.882241 140344161339264 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0226 07:37:05.882493 140344161339264 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0226 07:37:06.207930 140344161339264 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0226 07:37:06.208180 140344161339264 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0226 07:37:06.841051 140344161339264 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0226 07:37:06.841286 140344161339264 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0226 07:37:06.946193 140344161339264 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0226 07:37:06.989207 140344161339264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0226 07:37:07.055549 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0226 07:37:07.055770 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0226 07:37:07.055909 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0226 07:37:07.058112 140344161339264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0226 07:37:07.082773 140344161339264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0226 07:37:07.083097 140344161339264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0226 07:37:07.249328 140344161339264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0226 07:37:07.249560 140344161339264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0226 07:37:07.582475 140344161339264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0226 07:37:07.582727 140344161339264 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0226 07:37:07.899649 140344161339264 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0226 07:37:07.899884 140344161339264 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0226 07:37:08.311320 140344161339264 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0226 07:37:08.311724 140344161339264 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0226 07:37:08.761763 140344161339264 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0226 07:37:08.762020 140344161339264 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0226 07:37:09.304903 140344161339264 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0226 07:37:09.305136 140344161339264 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0226 07:37:09.504641 140344161339264 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0226 07:37:09.554374 140344161339264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0226 07:37:09.647766 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0226 07:37:09.647998 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0226 07:37:09.648116 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0226 07:37:09.650225 140344161339264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0226 07:37:09.670729 140344161339264 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0226 07:37:09.670898 140344161339264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0226 07:37:09.839697 140344161339264 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0226 07:37:09.839914 140344161339264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0226 07:37:10.149146 140344161339264 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0226 07:37:10.149385 140344161339264 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0226 07:37:10.463324 140344161339264 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0226 07:37:10.463547 140344161339264 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0226 07:37:10.896369 140344161339264 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0226 07:37:10.896604 140344161339264 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0226 07:37:11.339325 140344161339264 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0226 07:37:11.339562 140344161339264 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0226 07:37:11.866687 140344161339264 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0226 07:37:11.866916 140344161339264 efficientnet_model.py:144] round_filter input=320 output=352\n",
            "I0226 07:37:12.064008 140344161339264 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
            "I0226 07:37:12.101789 140344161339264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0226 07:37:12.188309 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0226 07:37:12.188520 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0226 07:37:12.188634 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0226 07:37:12.190771 140344161339264 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0226 07:37:12.212168 140344161339264 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0226 07:37:12.212309 140344161339264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0226 07:37:12.632503 140344161339264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0226 07:37:12.632738 140344161339264 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0226 07:37:12.947020 140344161339264 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0226 07:37:12.947262 140344161339264 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0226 07:37:13.247774 140344161339264 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0226 07:37:13.248003 140344161339264 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0226 07:37:13.782808 140344161339264 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0226 07:37:13.783038 140344161339264 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0226 07:37:14.332383 140344161339264 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0226 07:37:14.332643 140344161339264 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0226 07:37:14.972379 140344161339264 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0226 07:37:14.972659 140344161339264 efficientnet_model.py:144] round_filter input=320 output=384\n",
            "I0226 07:37:15.170244 140344161339264 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
            "I0226 07:37:15.210248 140344161339264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0226 07:37:15.300445 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0226 07:37:15.300668 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0226 07:37:15.300799 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0226 07:37:15.302916 140344161339264 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0226 07:37:15.324250 140344161339264 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0226 07:37:15.324401 140344161339264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0226 07:37:15.483417 140344161339264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0226 07:37:15.483642 140344161339264 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0226 07:37:15.902128 140344161339264 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0226 07:37:15.902336 140344161339264 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0226 07:37:16.314439 140344161339264 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0226 07:37:16.314722 140344161339264 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0226 07:37:16.952774 140344161339264 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0226 07:37:16.953024 140344161339264 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0226 07:37:17.597562 140344161339264 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0226 07:37:17.597795 140344161339264 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0226 07:37:18.447882 140344161339264 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0226 07:37:18.448158 140344161339264 efficientnet_model.py:144] round_filter input=320 output=448\n",
            "I0226 07:37:18.648480 140344161339264 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
            "I0226 07:37:18.691789 140344161339264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0226 07:37:19.040925 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0226 07:37:19.041183 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0226 07:37:19.041304 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0226 07:37:19.043339 140344161339264 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0226 07:37:19.063615 140344161339264 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0226 07:37:19.063774 140344161339264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0226 07:37:19.312271 140344161339264 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0226 07:37:19.312542 140344161339264 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0226 07:37:19.863315 140344161339264 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0226 07:37:19.863536 140344161339264 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0226 07:37:20.392849 140344161339264 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0226 07:37:20.393097 140344161339264 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0226 07:37:21.142866 140344161339264 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0226 07:37:21.143090 140344161339264 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0226 07:37:21.866660 140344161339264 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0226 07:37:21.866910 140344161339264 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0226 07:37:22.828918 140344161339264 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0226 07:37:22.829161 140344161339264 efficientnet_model.py:144] round_filter input=320 output=512\n",
            "I0226 07:37:23.164882 140344161339264 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
            "I0226 07:37:23.204872 140344161339264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0226 07:37:23.315085 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0226 07:37:23.315289 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0226 07:37:23.315400 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0226 07:37:23.317516 140344161339264 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0226 07:37:23.338957 140344161339264 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0226 07:37:23.339117 140344161339264 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0226 07:37:23.588928 140344161339264 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0226 07:37:23.589183 140344161339264 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0226 07:37:24.218761 140344161339264 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0226 07:37:24.219002 140344161339264 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0226 07:37:24.862878 140344161339264 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0226 07:37:24.863117 140344161339264 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0226 07:37:25.732751 140344161339264 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0226 07:37:25.733028 140344161339264 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0226 07:37:26.928763 140344161339264 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0226 07:37:26.929022 140344161339264 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0226 07:37:28.082700 140344161339264 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0226 07:37:28.082949 140344161339264 efficientnet_model.py:144] round_filter input=320 output=576\n",
            "I0226 07:37:28.404055 140344161339264 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
            "I0226 07:37:28.445369 140344161339264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0226 07:37:28.577482 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0226 07:37:28.577708 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0226 07:37:28.577845 140344161339264 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0226 07:37:28.580119 140344161339264 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0226 07:37:28.601650 140344161339264 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0226 07:37:28.601876 140344161339264 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0226 07:37:28.944570 140344161339264 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0226 07:37:28.944814 140344161339264 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0226 07:37:29.683548 140344161339264 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0226 07:37:29.683799 140344161339264 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0226 07:37:30.438828 140344161339264 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0226 07:37:30.439051 140344161339264 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0226 07:37:31.512866 140344161339264 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0226 07:37:31.513085 140344161339264 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0226 07:37:32.584566 140344161339264 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0226 07:37:32.584814 140344161339264 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0226 07:37:33.962496 140344161339264 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0226 07:37:33.962728 140344161339264 efficientnet_model.py:144] round_filter input=320 output=640\n",
            "I0226 07:37:34.729088 140344161339264 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
            "I0226 07:37:34.768477 140344161339264 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 30.17s\n",
            "I0226 07:37:34.937681 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 30.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0226 07:37:34.945115 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0226 07:37:34.947331 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0226 07:37:34.948029 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0226 07:37:34.951246 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0226 07:37:34.954435 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0226 07:37:34.955098 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0226 07:37:34.956435 140344161339264 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 39.075s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2B7lQiMc9c4",
        "outputId": "6d15f6e5-21de-4f06-c2ac-7488fb24af5e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "if error is this one:\n",
        "\n",
        "Traceback (most recent call last):\n",
        "  File \"generate_tfrecord.py\", line 76, in <module>\n",
        "    tf.app.run()\n",
        "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 48, in run\n",
        "    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n",
        "  File \"generate_tfrecord.py\", line 69, in main\n",
        "    tf_example = create_tf_example(row)\n",
        "  File \"generate_tfrecord.py\", line 60, in create_tf_example\n",
        "    'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "  File \"/home/j/Lib/models/object_detection/utils/dataset_util.py\", line 26, in int64_list_feature\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "TypeError: None has type NoneType, but expected one of: int, long\n",
        "\n",
        "\n",
        "then you should do this:\n",
        "\n",
        "\"The solution is a simple one.\n",
        "\n",
        "You just need to change the else statement so it returns 0 instead of \"None\".\n",
        "\n",
        "def class_text_to_int(row_label): if row_label == '<YOUR LABEL NAME>': return 1 else: return 0\n",
        "\n",
        "You can find def class_text_to_int in the generate_tfrecord.py file.\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "T0P4vd7y-arn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/models/research/preprocessing'\n",
        "print(os.getcwd())\n",
        "!python generate_tfrecords.py --csv_input=/content/train_labels.csv --image_dir=/content/train --output_path=/content/train.record"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyjy6JFZs1nm",
        "outputId": "f3f06860-46d7-46cc-bcb3-a6f84519eebc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/preprocessing\n",
            "/content/models/research/preprocessing\n",
            "Successfully created the TFRecords: /content/train.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_tfrecords.py --csv_input=/content/test_labels.csv --image_dir=/content/test --output_path=/content/test.record"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liA7NuIMvf58",
        "outputId": "8c4074af-423a-4140-b781-0be19b797350"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecords: /content/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/train \n",
        "# !rm -rf /content/test"
      ],
      "metadata": {
        "id": "Cyygv-z5-RCD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **detection** \n",
        "1- make a directory in the object detection folder named as 'standford_train'(in our case). \n",
        "\n",
        "2- choose a model from 'models/research/object_detection/g3doc/tf2_detection_zoo.md', we are choosing 'ssd_resnet152_v1_fpn_640x640_coco17_tpu-8' then download it and copy 'pipeline.config' and paste it in standford_train directory \n",
        "\n",
        "3- change the num_classes to the our total number of classes, should change batch_size to less than 5, change 'fine_tune_checkpoint_type = classification' to 'fine_tune_checkpoint_type = detection'  \n",
        "\n",
        "4- 'fine_tune_checkpint' file should be in the downloaded folder"
      ],
      "metadata": {
        "id": "0NBofjbeRizB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/models/research/object_detection'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxw0HkWX_JgA",
        "outputId": "fee28129-249f-4d30-e531-d52159cc90be"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/object_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless==4.5.5.62\n",
        "!pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "Vj5HuZ8a3KmQ",
        "outputId": "d3a737e1-f90f-4c53-c02d-836179e51e74"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.5.62\n",
            "Uninstalling opencv-python-headless-4.5.5.62:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.5.62.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-64ac49e1.so.58.91.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-4b79e479.so.58.45.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-805734e8.so.56.51.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-018b8c17.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libpng15-ce838cd1.so.15.13.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-6082116c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-83ce3247.so.3.7.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-7e960168.so.5.7.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-392cd848.so.6.4.0\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled opencv-python-headless-4.5.5.62\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 125 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "if training stuck because of memory, then either reduce the batch size or reduce the height and width of the image \n",
        "in \"pipeline.cofig\" \n",
        "'''"
      ],
      "metadata": {
        "id": "fwqvTi42Z8Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_main_tf2.py --model_dir=/content/models/research/object_detection/standford_train --pipeline_config_path=/content/models/research/object_detection/standford_train/pipeline.config --alsologtostderr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQdNh-J5MUc1",
        "outputId": "206ff90e-9aab-464e-82fb-20d8e16f337b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-26 08:34:06.826672: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0226 08:34:06.902426 139628655433600 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0226 08:34:06.907952 139628655433600 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0226 08:34:06.908156 139628655433600 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0226 08:34:07.093298 139628655433600 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/train.record']\n",
            "I0226 08:34:07.168309 139628655433600 dataset_builder.py:163] Reading unweighted datasets: ['/content/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/train.record']\n",
            "I0226 08:34:07.169028 139628655433600 dataset_builder.py:80] Reading record datasets for input file: ['/content/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0226 08:34:07.169198 139628655433600 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0226 08:34:07.169367 139628655433600 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0226 08:34:07.184886 139628655433600 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0226 08:34:07.238363 139628655433600 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0226 08:34:15.979512 139628655433600 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0226 08:34:19.871680 139628655433600 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0226 08:34:21.855090 139628655433600 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0226 08:35:11.939672 139628655433600 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0226 08:35:11.941336 139628655433600 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0226 08:35:11.944498 139628655433600 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0226 08:35:11.945758 139628655433600 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0226 08:35:11.949090 139628655433600 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0226 08:35:11.950363 139628655433600 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0226 08:35:11.954148 139628655433600 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0226 08:35:11.955469 139628655433600 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0226 08:35:11.958244 139628655433600 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0226 08:35:11.959536 139628655433600 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0226 08:35:13.979216 139623935080192 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 2.378s\n",
            "I0226 08:39:11.352601 139628655433600 model_lib_v2.py:707] Step 100 per-step time 2.378s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.0396878,\n",
            " 'Loss/localization_loss': 0.3837612,\n",
            " 'Loss/regularization_loss': 0.5174385,\n",
            " 'Loss/total_loss': 1.9408875,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0226 08:39:11.353121 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.0396878,\n",
            " 'Loss/localization_loss': 0.3837612,\n",
            " 'Loss/regularization_loss': 0.5174385,\n",
            " 'Loss/total_loss': 1.9408875,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 1.770s\n",
            "I0226 08:42:08.137022 139628655433600 model_lib_v2.py:707] Step 200 per-step time 1.770s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.83503157,\n",
            " 'Loss/localization_loss': 0.42563945,\n",
            " 'Loss/regularization_loss': 0.5167054,\n",
            " 'Loss/total_loss': 1.7773764,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0226 08:42:08.137518 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.83503157,\n",
            " 'Loss/localization_loss': 0.42563945,\n",
            " 'Loss/regularization_loss': 0.5167054,\n",
            " 'Loss/total_loss': 1.7773764,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 1.765s\n",
            "I0226 08:45:04.611698 139628655433600 model_lib_v2.py:707] Step 300 per-step time 1.765s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.9297759,\n",
            " 'Loss/localization_loss': 0.45650557,\n",
            " 'Loss/regularization_loss': 0.51335233,\n",
            " 'Loss/total_loss': 1.8996338,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0226 08:45:04.612134 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.9297759,\n",
            " 'Loss/localization_loss': 0.45650557,\n",
            " 'Loss/regularization_loss': 0.51335233,\n",
            " 'Loss/total_loss': 1.8996338,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 1.764s\n",
            "I0226 08:48:01.044598 139628655433600 model_lib_v2.py:707] Step 400 per-step time 1.764s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.2927407,\n",
            " 'Loss/localization_loss': 0.18274298,\n",
            " 'Loss/regularization_loss': 0.51066387,\n",
            " 'Loss/total_loss': 1.9861475,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0226 08:48:01.045077 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.2927407,\n",
            " 'Loss/localization_loss': 0.18274298,\n",
            " 'Loss/regularization_loss': 0.51066387,\n",
            " 'Loss/total_loss': 1.9861475,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 1.771s\n",
            "I0226 08:50:58.099951 139628655433600 model_lib_v2.py:707] Step 500 per-step time 1.771s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.34203872,\n",
            " 'Loss/localization_loss': 0.17463711,\n",
            " 'Loss/regularization_loss': 0.50990117,\n",
            " 'Loss/total_loss': 1.026577,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0226 08:50:58.100376 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.34203872,\n",
            " 'Loss/localization_loss': 0.17463711,\n",
            " 'Loss/regularization_loss': 0.50990117,\n",
            " 'Loss/total_loss': 1.026577,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 1.775s\n",
            "I0226 08:53:55.554004 139628655433600 model_lib_v2.py:707] Step 600 per-step time 1.775s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.2931089,\n",
            " 'Loss/localization_loss': 0.18608683,\n",
            " 'Loss/regularization_loss': 0.54012275,\n",
            " 'Loss/total_loss': 2.0193186,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0226 08:53:55.554450 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.2931089,\n",
            " 'Loss/localization_loss': 0.18608683,\n",
            " 'Loss/regularization_loss': 0.54012275,\n",
            " 'Loss/total_loss': 2.0193186,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 1.775s\n",
            "I0226 08:56:53.059899 139628655433600 model_lib_v2.py:707] Step 700 per-step time 1.775s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.49392733,\n",
            " 'Loss/localization_loss': 0.1831982,\n",
            " 'Loss/regularization_loss': 0.5793346,\n",
            " 'Loss/total_loss': 1.2564602,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0226 08:56:53.060381 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.49392733,\n",
            " 'Loss/localization_loss': 0.1831982,\n",
            " 'Loss/regularization_loss': 0.5793346,\n",
            " 'Loss/total_loss': 1.2564602,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 1.775s\n",
            "I0226 08:59:50.549046 139628655433600 model_lib_v2.py:707] Step 800 per-step time 1.775s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.77034503,\n",
            " 'Loss/localization_loss': 0.37573045,\n",
            " 'Loss/regularization_loss': 0.5728625,\n",
            " 'Loss/total_loss': 1.7189381,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0226 08:59:50.549512 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.77034503,\n",
            " 'Loss/localization_loss': 0.37573045,\n",
            " 'Loss/regularization_loss': 0.5728625,\n",
            " 'Loss/total_loss': 1.7189381,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 1.774s\n",
            "I0226 09:02:47.935887 139628655433600 model_lib_v2.py:707] Step 900 per-step time 1.774s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.69067943,\n",
            " 'Loss/localization_loss': 0.1654775,\n",
            " 'Loss/regularization_loss': 0.5640288,\n",
            " 'Loss/total_loss': 1.4201858,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0226 09:02:47.936377 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.69067943,\n",
            " 'Loss/localization_loss': 0.1654775,\n",
            " 'Loss/regularization_loss': 0.5640288,\n",
            " 'Loss/total_loss': 1.4201858,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.772s\n",
            "I0226 09:05:45.121973 139628655433600 model_lib_v2.py:707] Step 1000 per-step time 1.772s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.840594,\n",
            " 'Loss/localization_loss': 0.27608642,\n",
            " 'Loss/regularization_loss': 0.558925,\n",
            " 'Loss/total_loss': 1.6756054,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0226 09:05:45.122464 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.840594,\n",
            " 'Loss/localization_loss': 0.27608642,\n",
            " 'Loss/regularization_loss': 0.558925,\n",
            " 'Loss/total_loss': 1.6756054,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.795s\n",
            "I0226 09:08:44.582977 139628655433600 model_lib_v2.py:707] Step 1100 per-step time 1.795s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.70289576,\n",
            " 'Loss/localization_loss': 0.2749113,\n",
            " 'Loss/regularization_loss': 0.55197287,\n",
            " 'Loss/total_loss': 1.5297799,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0226 09:08:44.583412 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.70289576,\n",
            " 'Loss/localization_loss': 0.2749113,\n",
            " 'Loss/regularization_loss': 0.55197287,\n",
            " 'Loss/total_loss': 1.5297799,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.771s\n",
            "I0226 09:11:41.640426 139628655433600 model_lib_v2.py:707] Step 1200 per-step time 1.771s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.6194964,\n",
            " 'Loss/localization_loss': 0.17337981,\n",
            " 'Loss/regularization_loss': 0.54759145,\n",
            " 'Loss/total_loss': 1.3404676,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0226 09:11:41.640937 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.6194964,\n",
            " 'Loss/localization_loss': 0.17337981,\n",
            " 'Loss/regularization_loss': 0.54759145,\n",
            " 'Loss/total_loss': 1.3404676,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.770s\n",
            "I0226 09:14:38.598058 139628655433600 model_lib_v2.py:707] Step 1300 per-step time 1.770s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7857952,\n",
            " 'Loss/localization_loss': 0.085254155,\n",
            " 'Loss/regularization_loss': 0.53798306,\n",
            " 'Loss/total_loss': 1.4090325,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0226 09:14:38.598497 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.7857952,\n",
            " 'Loss/localization_loss': 0.085254155,\n",
            " 'Loss/regularization_loss': 0.53798306,\n",
            " 'Loss/total_loss': 1.4090325,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 1.769s\n",
            "I0226 09:17:35.511929 139628655433600 model_lib_v2.py:707] Step 1400 per-step time 1.769s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.6542434,\n",
            " 'Loss/localization_loss': 0.25868556,\n",
            " 'Loss/regularization_loss': 0.5286054,\n",
            " 'Loss/total_loss': 1.4415344,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0226 09:17:35.512373 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.6542434,\n",
            " 'Loss/localization_loss': 0.25868556,\n",
            " 'Loss/regularization_loss': 0.5286054,\n",
            " 'Loss/total_loss': 1.4415344,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.769s\n",
            "I0226 09:20:32.415557 139628655433600 model_lib_v2.py:707] Step 1500 per-step time 1.769s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.8709116,\n",
            " 'Loss/localization_loss': 0.13723135,\n",
            " 'Loss/regularization_loss': 0.64893246,\n",
            " 'Loss/total_loss': 1.6570754,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0226 09:20:32.416022 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.8709116,\n",
            " 'Loss/localization_loss': 0.13723135,\n",
            " 'Loss/regularization_loss': 0.64893246,\n",
            " 'Loss/total_loss': 1.6570754,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.769s\n",
            "I0226 09:23:29.348024 139628655433600 model_lib_v2.py:707] Step 1600 per-step time 1.769s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.99634945,\n",
            " 'Loss/localization_loss': 0.24849859,\n",
            " 'Loss/regularization_loss': 83.34901,\n",
            " 'Loss/total_loss': 84.59386,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0226 09:23:29.348546 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.99634945,\n",
            " 'Loss/localization_loss': 0.24849859,\n",
            " 'Loss/regularization_loss': 83.34901,\n",
            " 'Loss/total_loss': 84.59386,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.772s\n",
            "I0226 09:26:26.573690 139628655433600 model_lib_v2.py:707] Step 1700 per-step time 1.772s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.9868056,\n",
            " 'Loss/localization_loss': 0.56300616,\n",
            " 'Loss/regularization_loss': 82.22368,\n",
            " 'Loss/total_loss': 83.77349,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0226 09:26:26.574138 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.9868056,\n",
            " 'Loss/localization_loss': 0.56300616,\n",
            " 'Loss/regularization_loss': 82.22368,\n",
            " 'Loss/total_loss': 83.77349,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.767s\n",
            "I0226 09:29:23.294443 139628655433600 model_lib_v2.py:707] Step 1800 per-step time 1.767s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.0819718,\n",
            " 'Loss/localization_loss': 0.43427193,\n",
            " 'Loss/regularization_loss': 79.93878,\n",
            " 'Loss/total_loss': 81.455025,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0226 09:29:23.294916 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.0819718,\n",
            " 'Loss/localization_loss': 0.43427193,\n",
            " 'Loss/regularization_loss': 79.93878,\n",
            " 'Loss/total_loss': 81.455025,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.763s\n",
            "I0226 09:32:19.643811 139628655433600 model_lib_v2.py:707] Step 1900 per-step time 1.763s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.8634291,\n",
            " 'Loss/localization_loss': 0.23161516,\n",
            " 'Loss/regularization_loss': 293.3772,\n",
            " 'Loss/total_loss': 294.47226,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0226 09:32:19.644226 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.8634291,\n",
            " 'Loss/localization_loss': 0.23161516,\n",
            " 'Loss/regularization_loss': 293.3772,\n",
            " 'Loss/total_loss': 294.47226,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.756s\n",
            "I0226 09:35:15.201006 139628655433600 model_lib_v2.py:707] Step 2000 per-step time 1.756s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.0214263,\n",
            " 'Loss/localization_loss': 0.2008001,\n",
            " 'Loss/regularization_loss': 341.48553,\n",
            " 'Loss/total_loss': 342.70776,\n",
            " 'learning_rate': 0.04}\n",
            "I0226 09:35:15.201460 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.0214263,\n",
            " 'Loss/localization_loss': 0.2008001,\n",
            " 'Loss/regularization_loss': 341.48553,\n",
            " 'Loss/total_loss': 342.70776,\n",
            " 'learning_rate': 0.04}\n",
            "INFO:tensorflow:Step 2100 per-step time 1.780s\n",
            "I0226 09:38:13.153660 139628655433600 model_lib_v2.py:707] Step 2100 per-step time 1.780s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7570321,\n",
            " 'Loss/localization_loss': 0.16752145,\n",
            " 'Loss/regularization_loss': 330.9788,\n",
            " 'Loss/total_loss': 331.90332,\n",
            " 'learning_rate': 0.039999895}\n",
            "I0226 09:38:13.154126 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.7570321,\n",
            " 'Loss/localization_loss': 0.16752145,\n",
            " 'Loss/regularization_loss': 330.9788,\n",
            " 'Loss/total_loss': 331.90332,\n",
            " 'learning_rate': 0.039999895}\n",
            "INFO:tensorflow:Step 2200 per-step time 1.754s\n",
            "I0226 09:41:08.536892 139628655433600 model_lib_v2.py:707] Step 2200 per-step time 1.754s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.1947345,\n",
            " 'Loss/localization_loss': 0.21188115,\n",
            " 'Loss/regularization_loss': 322.8353,\n",
            " 'Loss/total_loss': 324.2419,\n",
            " 'learning_rate': 0.03999959}\n",
            "I0226 09:41:08.537351 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.1947345,\n",
            " 'Loss/localization_loss': 0.21188115,\n",
            " 'Loss/regularization_loss': 322.8353,\n",
            " 'Loss/total_loss': 324.2419,\n",
            " 'learning_rate': 0.03999959}\n",
            "INFO:tensorflow:Step 2300 per-step time 1.752s\n",
            "I0226 09:44:03.787111 139628655433600 model_lib_v2.py:707] Step 2300 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.9194664,\n",
            " 'Loss/localization_loss': 0.29993248,\n",
            " 'Loss/regularization_loss': 312.67178,\n",
            " 'Loss/total_loss': 313.89117,\n",
            " 'learning_rate': 0.039999075}\n",
            "I0226 09:44:03.787584 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.9194664,\n",
            " 'Loss/localization_loss': 0.29993248,\n",
            " 'Loss/regularization_loss': 312.67178,\n",
            " 'Loss/total_loss': 313.89117,\n",
            " 'learning_rate': 0.039999075}\n",
            "INFO:tensorflow:Step 2400 per-step time 1.753s\n",
            "I0226 09:46:59.048068 139628655433600 model_lib_v2.py:707] Step 2400 per-step time 1.753s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.48751062,\n",
            " 'Loss/localization_loss': 0.19265962,\n",
            " 'Loss/regularization_loss': 302.85458,\n",
            " 'Loss/total_loss': 303.53476,\n",
            " 'learning_rate': 0.039998353}\n",
            "I0226 09:46:59.048469 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.48751062,\n",
            " 'Loss/localization_loss': 0.19265962,\n",
            " 'Loss/regularization_loss': 302.85458,\n",
            " 'Loss/total_loss': 303.53476,\n",
            " 'learning_rate': 0.039998353}\n",
            "INFO:tensorflow:Step 2500 per-step time 1.755s\n",
            "I0226 09:49:54.512064 139628655433600 model_lib_v2.py:707] Step 2500 per-step time 1.755s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7898966,\n",
            " 'Loss/localization_loss': 0.055579007,\n",
            " 'Loss/regularization_loss': 293.3087,\n",
            " 'Loss/total_loss': 294.15414,\n",
            " 'learning_rate': 0.03999743}\n",
            "I0226 09:49:54.512678 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.7898966,\n",
            " 'Loss/localization_loss': 0.055579007,\n",
            " 'Loss/regularization_loss': 293.3087,\n",
            " 'Loss/total_loss': 294.15414,\n",
            " 'learning_rate': 0.03999743}\n",
            "INFO:tensorflow:Step 2600 per-step time 1.754s\n",
            "I0226 09:52:49.909826 139628655433600 model_lib_v2.py:707] Step 2600 per-step time 1.754s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.2084078,\n",
            " 'Loss/localization_loss': 0.15940058,\n",
            " 'Loss/regularization_loss': 284.0635,\n",
            " 'Loss/total_loss': 285.4313,\n",
            " 'learning_rate': 0.0399963}\n",
            "I0226 09:52:49.910288 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.2084078,\n",
            " 'Loss/localization_loss': 0.15940058,\n",
            " 'Loss/regularization_loss': 284.0635,\n",
            " 'Loss/total_loss': 285.4313,\n",
            " 'learning_rate': 0.0399963}\n",
            "INFO:tensorflow:Step 2700 per-step time 1.756s\n",
            "I0226 09:55:45.528605 139628655433600 model_lib_v2.py:707] Step 2700 per-step time 1.756s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7509691,\n",
            " 'Loss/localization_loss': 0.31096894,\n",
            " 'Loss/regularization_loss': 275.12207,\n",
            " 'Loss/total_loss': 276.18402,\n",
            " 'learning_rate': 0.039994963}\n",
            "I0226 09:55:45.529083 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.7509691,\n",
            " 'Loss/localization_loss': 0.31096894,\n",
            " 'Loss/regularization_loss': 275.12207,\n",
            " 'Loss/total_loss': 276.18402,\n",
            " 'learning_rate': 0.039994963}\n",
            "INFO:tensorflow:Step 2800 per-step time 1.753s\n",
            "I0226 09:58:40.790446 139628655433600 model_lib_v2.py:707] Step 2800 per-step time 1.753s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.82942694,\n",
            " 'Loss/localization_loss': 0.637885,\n",
            " 'Loss/regularization_loss': 266.45087,\n",
            " 'Loss/total_loss': 267.91818,\n",
            " 'learning_rate': 0.039993424}\n",
            "I0226 09:58:40.791098 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.82942694,\n",
            " 'Loss/localization_loss': 0.637885,\n",
            " 'Loss/regularization_loss': 266.45087,\n",
            " 'Loss/total_loss': 267.91818,\n",
            " 'learning_rate': 0.039993424}\n",
            "INFO:tensorflow:Step 2900 per-step time 1.752s\n",
            "I0226 10:01:35.980047 139628655433600 model_lib_v2.py:707] Step 2900 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.67605305,\n",
            " 'Loss/localization_loss': 0.18865186,\n",
            " 'Loss/regularization_loss': 258.05508,\n",
            " 'Loss/total_loss': 258.9198,\n",
            " 'learning_rate': 0.039991677}\n",
            "I0226 10:01:35.980442 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.67605305,\n",
            " 'Loss/localization_loss': 0.18865186,\n",
            " 'Loss/regularization_loss': 258.05508,\n",
            " 'Loss/total_loss': 258.9198,\n",
            " 'learning_rate': 0.039991677}\n",
            "INFO:tensorflow:Step 3000 per-step time 1.753s\n",
            "I0226 10:04:31.233261 139628655433600 model_lib_v2.py:707] Step 3000 per-step time 1.753s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.62916666,\n",
            " 'Loss/localization_loss': 0.1978803,\n",
            " 'Loss/regularization_loss': 249.9197,\n",
            " 'Loss/total_loss': 250.74673,\n",
            " 'learning_rate': 0.039989725}\n",
            "I0226 10:04:31.233698 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.62916666,\n",
            " 'Loss/localization_loss': 0.1978803,\n",
            " 'Loss/regularization_loss': 249.9197,\n",
            " 'Loss/total_loss': 250.74673,\n",
            " 'learning_rate': 0.039989725}\n",
            "INFO:tensorflow:Step 3100 per-step time 1.780s\n",
            "I0226 10:07:29.199460 139628655433600 model_lib_v2.py:707] Step 3100 per-step time 1.780s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.843719,\n",
            " 'Loss/localization_loss': 0.33622012,\n",
            " 'Loss/regularization_loss': 242.04175,\n",
            " 'Loss/total_loss': 243.2217,\n",
            " 'learning_rate': 0.039987564}\n",
            "I0226 10:07:29.199913 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.843719,\n",
            " 'Loss/localization_loss': 0.33622012,\n",
            " 'Loss/regularization_loss': 242.04175,\n",
            " 'Loss/total_loss': 243.2217,\n",
            " 'learning_rate': 0.039987564}\n",
            "INFO:tensorflow:Step 3200 per-step time 1.752s\n",
            "I0226 10:10:24.356590 139628655433600 model_lib_v2.py:707] Step 3200 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.8736506,\n",
            " 'Loss/localization_loss': 0.17681189,\n",
            " 'Loss/regularization_loss': 234.41235,\n",
            " 'Loss/total_loss': 235.46283,\n",
            " 'learning_rate': 0.039985202}\n",
            "I0226 10:10:24.357044 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.8736506,\n",
            " 'Loss/localization_loss': 0.17681189,\n",
            " 'Loss/regularization_loss': 234.41235,\n",
            " 'Loss/total_loss': 235.46283,\n",
            " 'learning_rate': 0.039985202}\n",
            "INFO:tensorflow:Step 3300 per-step time 1.752s\n",
            "I0226 10:13:19.510437 139628655433600 model_lib_v2.py:707] Step 3300 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.904977,\n",
            " 'Loss/localization_loss': 0.04431408,\n",
            " 'Loss/regularization_loss': 227.02396,\n",
            " 'Loss/total_loss': 227.97325,\n",
            " 'learning_rate': 0.03998263}\n",
            "I0226 10:13:19.510887 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.904977,\n",
            " 'Loss/localization_loss': 0.04431408,\n",
            " 'Loss/regularization_loss': 227.02396,\n",
            " 'Loss/total_loss': 227.97325,\n",
            " 'learning_rate': 0.03998263}\n",
            "INFO:tensorflow:Step 3400 per-step time 1.753s\n",
            "I0226 10:16:14.771116 139628655433600 model_lib_v2.py:707] Step 3400 per-step time 1.753s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.9173564,\n",
            " 'Loss/localization_loss': 0.25088754,\n",
            " 'Loss/regularization_loss': 219.8688,\n",
            " 'Loss/total_loss': 221.03705,\n",
            " 'learning_rate': 0.03997986}\n",
            "I0226 10:16:14.771539 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.9173564,\n",
            " 'Loss/localization_loss': 0.25088754,\n",
            " 'Loss/regularization_loss': 219.8688,\n",
            " 'Loss/total_loss': 221.03705,\n",
            " 'learning_rate': 0.03997986}\n",
            "INFO:tensorflow:Step 3500 per-step time 1.752s\n",
            "I0226 10:19:10.005212 139628655433600 model_lib_v2.py:707] Step 3500 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.0442219,\n",
            " 'Loss/localization_loss': 0.21188657,\n",
            " 'Loss/regularization_loss': 212.94084,\n",
            " 'Loss/total_loss': 214.19695,\n",
            " 'learning_rate': 0.039976884}\n",
            "I0226 10:19:10.005644 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.0442219,\n",
            " 'Loss/localization_loss': 0.21188657,\n",
            " 'Loss/regularization_loss': 212.94084,\n",
            " 'Loss/total_loss': 214.19695,\n",
            " 'learning_rate': 0.039976884}\n",
            "INFO:tensorflow:Step 3600 per-step time 1.752s\n",
            "I0226 10:22:05.175301 139628655433600 model_lib_v2.py:707] Step 3600 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.69525087,\n",
            " 'Loss/localization_loss': 0.08080009,\n",
            " 'Loss/regularization_loss': 206.23038,\n",
            " 'Loss/total_loss': 207.00642,\n",
            " 'learning_rate': 0.0399737}\n",
            "I0226 10:22:05.175776 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.69525087,\n",
            " 'Loss/localization_loss': 0.08080009,\n",
            " 'Loss/regularization_loss': 206.23038,\n",
            " 'Loss/total_loss': 207.00642,\n",
            " 'learning_rate': 0.0399737}\n",
            "INFO:tensorflow:Step 3700 per-step time 1.752s\n",
            "I0226 10:25:00.345616 139628655433600 model_lib_v2.py:707] Step 3700 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7622868,\n",
            " 'Loss/localization_loss': 0.19478433,\n",
            " 'Loss/regularization_loss': 199.7322,\n",
            " 'Loss/total_loss': 200.68925,\n",
            " 'learning_rate': 0.039970305}\n",
            "I0226 10:25:00.346091 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.7622868,\n",
            " 'Loss/localization_loss': 0.19478433,\n",
            " 'Loss/regularization_loss': 199.7322,\n",
            " 'Loss/total_loss': 200.68925,\n",
            " 'learning_rate': 0.039970305}\n",
            "INFO:tensorflow:Step 3800 per-step time 1.753s\n",
            "I0226 10:27:55.605812 139628655433600 model_lib_v2.py:707] Step 3800 per-step time 1.753s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.69711953,\n",
            " 'Loss/localization_loss': 0.04422165,\n",
            " 'Loss/regularization_loss': 193.44005,\n",
            " 'Loss/total_loss': 194.18138,\n",
            " 'learning_rate': 0.03996671}\n",
            "I0226 10:27:55.606219 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.69711953,\n",
            " 'Loss/localization_loss': 0.04422165,\n",
            " 'Loss/regularization_loss': 193.44005,\n",
            " 'Loss/total_loss': 194.18138,\n",
            " 'learning_rate': 0.03996671}\n",
            "INFO:tensorflow:Step 3900 per-step time 1.752s\n",
            "I0226 10:30:50.762878 139628655433600 model_lib_v2.py:707] Step 3900 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.62877357,\n",
            " 'Loss/localization_loss': 0.20716222,\n",
            " 'Loss/regularization_loss': 187.34616,\n",
            " 'Loss/total_loss': 188.1821,\n",
            " 'learning_rate': 0.03996291}\n",
            "I0226 10:30:50.763396 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.62877357,\n",
            " 'Loss/localization_loss': 0.20716222,\n",
            " 'Loss/regularization_loss': 187.34616,\n",
            " 'Loss/total_loss': 188.1821,\n",
            " 'learning_rate': 0.03996291}\n",
            "INFO:tensorflow:Step 4000 per-step time 1.752s\n",
            "I0226 10:33:45.973018 139628655433600 model_lib_v2.py:707] Step 4000 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.0589914,\n",
            " 'Loss/localization_loss': 0.396192,\n",
            " 'Loss/regularization_loss': 181.44536,\n",
            " 'Loss/total_loss': 182.90054,\n",
            " 'learning_rate': 0.039958905}\n",
            "I0226 10:33:45.973449 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.0589914,\n",
            " 'Loss/localization_loss': 0.396192,\n",
            " 'Loss/regularization_loss': 181.44536,\n",
            " 'Loss/total_loss': 182.90054,\n",
            " 'learning_rate': 0.039958905}\n",
            "INFO:tensorflow:Step 4100 per-step time 1.777s\n",
            "I0226 10:36:43.694516 139628655433600 model_lib_v2.py:707] Step 4100 per-step time 1.777s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.72046787,\n",
            " 'Loss/localization_loss': 0.3714541,\n",
            " 'Loss/regularization_loss': 175.73479,\n",
            " 'Loss/total_loss': 176.82672,\n",
            " 'learning_rate': 0.039954696}\n",
            "I0226 10:36:43.694965 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.72046787,\n",
            " 'Loss/localization_loss': 0.3714541,\n",
            " 'Loss/regularization_loss': 175.73479,\n",
            " 'Loss/total_loss': 176.82672,\n",
            " 'learning_rate': 0.039954696}\n",
            "INFO:tensorflow:Step 4200 per-step time 1.752s\n",
            "I0226 10:39:38.887868 139628655433600 model_lib_v2.py:707] Step 4200 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.193747,\n",
            " 'Loss/localization_loss': 0.16461805,\n",
            " 'Loss/regularization_loss': 170.20024,\n",
            " 'Loss/total_loss': 171.5586,\n",
            " 'learning_rate': 0.03995028}\n",
            "I0226 10:39:38.888337 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.193747,\n",
            " 'Loss/localization_loss': 0.16461805,\n",
            " 'Loss/regularization_loss': 170.20024,\n",
            " 'Loss/total_loss': 171.5586,\n",
            " 'learning_rate': 0.03995028}\n",
            "INFO:tensorflow:Step 4300 per-step time 1.752s\n",
            "I0226 10:42:34.067095 139628655433600 model_lib_v2.py:707] Step 4300 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.67900157,\n",
            " 'Loss/localization_loss': 0.17491432,\n",
            " 'Loss/regularization_loss': 164.84142,\n",
            " 'Loss/total_loss': 165.69533,\n",
            " 'learning_rate': 0.039945662}\n",
            "I0226 10:42:34.067489 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.67900157,\n",
            " 'Loss/localization_loss': 0.17491432,\n",
            " 'Loss/regularization_loss': 164.84142,\n",
            " 'Loss/total_loss': 165.69533,\n",
            " 'learning_rate': 0.039945662}\n",
            "INFO:tensorflow:Step 4400 per-step time 1.752s\n",
            "I0226 10:45:29.305652 139628655433600 model_lib_v2.py:707] Step 4400 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.6322627,\n",
            " 'Loss/localization_loss': 0.5826067,\n",
            " 'Loss/regularization_loss': 159.65222,\n",
            " 'Loss/total_loss': 161.8671,\n",
            " 'learning_rate': 0.039940834}\n",
            "I0226 10:45:29.306055 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.6322627,\n",
            " 'Loss/localization_loss': 0.5826067,\n",
            " 'Loss/regularization_loss': 159.65222,\n",
            " 'Loss/total_loss': 161.8671,\n",
            " 'learning_rate': 0.039940834}\n",
            "INFO:tensorflow:Step 4500 per-step time 1.751s\n",
            "I0226 10:48:24.450930 139628655433600 model_lib_v2.py:707] Step 4500 per-step time 1.751s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.6200584,\n",
            " 'Loss/localization_loss': 0.13633353,\n",
            " 'Loss/regularization_loss': 154.6263,\n",
            " 'Loss/total_loss': 155.38269,\n",
            " 'learning_rate': 0.039935805}\n",
            "I0226 10:48:24.451331 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.6200584,\n",
            " 'Loss/localization_loss': 0.13633353,\n",
            " 'Loss/regularization_loss': 154.6263,\n",
            " 'Loss/total_loss': 155.38269,\n",
            " 'learning_rate': 0.039935805}\n",
            "INFO:tensorflow:Step 4600 per-step time 1.752s\n",
            "I0226 10:51:19.658986 139628655433600 model_lib_v2.py:707] Step 4600 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.7841441,\n",
            " 'Loss/localization_loss': 0.21583828,\n",
            " 'Loss/regularization_loss': 211.03378,\n",
            " 'Loss/total_loss': 212.03377,\n",
            " 'learning_rate': 0.03993057}\n",
            "I0226 10:51:19.659393 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.7841441,\n",
            " 'Loss/localization_loss': 0.21583828,\n",
            " 'Loss/regularization_loss': 211.03378,\n",
            " 'Loss/total_loss': 212.03377,\n",
            " 'learning_rate': 0.03993057}\n",
            "INFO:tensorflow:Step 4700 per-step time 1.755s\n",
            "I0226 10:54:15.134099 139628655433600 model_lib_v2.py:707] Step 4700 per-step time 1.755s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.62115765,\n",
            " 'Loss/localization_loss': 0.1547483,\n",
            " 'Loss/regularization_loss': 210.99254,\n",
            " 'Loss/total_loss': 211.76845,\n",
            " 'learning_rate': 0.039925132}\n",
            "I0226 10:54:15.134544 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.62115765,\n",
            " 'Loss/localization_loss': 0.1547483,\n",
            " 'Loss/regularization_loss': 210.99254,\n",
            " 'Loss/total_loss': 211.76845,\n",
            " 'learning_rate': 0.039925132}\n",
            "INFO:tensorflow:Step 4800 per-step time 1.752s\n",
            "I0226 10:57:10.370053 139628655433600 model_lib_v2.py:707] Step 4800 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.202929,\n",
            " 'Loss/localization_loss': 0.16541094,\n",
            " 'Loss/regularization_loss': 204.35246,\n",
            " 'Loss/total_loss': 205.7208,\n",
            " 'learning_rate': 0.039919484}\n",
            "I0226 10:57:10.370527 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.202929,\n",
            " 'Loss/localization_loss': 0.16541094,\n",
            " 'Loss/regularization_loss': 204.35246,\n",
            " 'Loss/total_loss': 205.7208,\n",
            " 'learning_rate': 0.039919484}\n",
            "INFO:tensorflow:Step 4900 per-step time 1.752s\n",
            "I0226 11:00:05.618641 139628655433600 model_lib_v2.py:707] Step 4900 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.837216,\n",
            " 'Loss/localization_loss': 0.18021314,\n",
            " 'Loss/regularization_loss': 197.92259,\n",
            " 'Loss/total_loss': 198.94002,\n",
            " 'learning_rate': 0.039913636}\n",
            "I0226 11:00:05.619086 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 0.837216,\n",
            " 'Loss/localization_loss': 0.18021314,\n",
            " 'Loss/regularization_loss': 197.92259,\n",
            " 'Loss/total_loss': 198.94002,\n",
            " 'learning_rate': 0.039913636}\n",
            "INFO:tensorflow:Step 5000 per-step time 1.752s\n",
            "I0226 11:03:00.777384 139628655433600 model_lib_v2.py:707] Step 5000 per-step time 1.752s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 1.1221439,\n",
            " 'Loss/localization_loss': 0.4891545,\n",
            " 'Loss/regularization_loss': 191.69626,\n",
            " 'Loss/total_loss': 193.30756,\n",
            " 'learning_rate': 0.039907582}\n",
            "I0226 11:03:00.777873 139628655433600 model_lib_v2.py:708] {'Loss/classification_loss': 1.1221439,\n",
            " 'Loss/localization_loss': 0.4891545,\n",
            " 'Loss/regularization_loss': 191.69626,\n",
            " 'Loss/total_loss': 193.30756,\n",
            " 'learning_rate': 0.039907582}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "PaGiaN45AX_C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}